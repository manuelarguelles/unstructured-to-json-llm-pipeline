# Unstructured Text â†’ Structured JSON Pipeline

> Convert raw text into validated, structured data using LLM agents

[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://python.org)
[![Pydantic](https://img.shields.io/badge/pydantic-v2-green.svg)](https://docs.pydantic.dev)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## Pipeline Overview

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Raw Text Files â”‚  (company descriptions, news, PDFs â†’ .txt)
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  LLM Extraction â”‚  Databricks Â· Llama 3.3 70B
 â”‚  (structured    â”‚  System prompt includes schema definition
 â”‚   prompting)    â”‚  Returns ONLY valid JSON
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Pydantic v2     â”‚  CompanyProfile / BuyerProfile
 â”‚ Validation      â”‚  Type coercion + custom validators
 â”‚ + Confidence    â”‚  0.0â€“1.0 confidence scoring
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ SQLite Storage  â”‚  Lineage: source_file, extracted_at,
 â”‚ (extractions.db)â”‚  model_version, confidence_score
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Features

- ğŸ¤– **LLM-powered extraction** â€” Llama 3.3 70B via Databricks Foundation Models (free tier)
- âœ… **Pydantic v2 validation** â€” strict typing, custom validators, clear error messages
- ğŸ“Š **Confidence scoring** â€” LLM self-reports extraction quality (0â€“1) per record
- ğŸ” **Data lineage** â€” every row tracks source file, timestamp, and model version
- ğŸ” **Retry logic** â€” automatic retries on API or parse failures with backoff

---

## Quickstart

```bash
# 1. Clone the repo
git clone https://github.com/manuelarguelles/unstructured-to-json-llm-pipeline.git
cd unstructured-to-json-llm-pipeline

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure credentials
cp .env.example .env
# Edit .env and add your DATABRICKS_TOKEN

# 4. Run the pipeline
python pipeline.py
```

---

## Example Output

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Unstructured â†’ Structured JSON Pipeline
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â†’ SQLite DB: extractions.db
â†’ Found 5 file(s) to process

â†’ Processing: acme_corp.txt  [CompanyProfile]
âœ” Acme Corporation â€” confidence: 0.94

â†’ Processing: globex_industries.txt  [CompanyProfile]
âœ” Globex Industries â€” confidence: 0.91

â†’ Processing: initech_capital.txt  [BuyerProfile]
âœ” Initech Capital Partners â€” confidence: 0.88

â†’ Processing: oceanic_analytics.txt  [CompanyProfile]
âœ” Oceanic Analytics â€” confidence: 0.95

â†’ Processing: wayne_enterprises.txt  [CompanyProfile]
âœ” Wayne Enterprises â€” confidence: 0.90

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
File                           Schema            Conf  Status
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
acme_corp.txt                  CompanyProfile    0.94  âœ… OK
globex_industries.txt          CompanyProfile    0.91  âœ… OK
initech_capital.txt            BuyerProfile      0.88  âœ… OK
oceanic_analytics.txt          CompanyProfile    0.95  âœ… OK
wayne_enterprises.txt          CompanyProfile    0.90  âœ… OK

Total: 5/5 successful extractions
```

**Extracted JSON example (acme_corp.txt â†’ CompanyProfile):**

```json
{
  "company_name": "Acme Corporation",
  "industry": "Cloud Infrastructure / SaaS",
  "headquarters": "San Francisco, CA",
  "employee_count": 1200,
  "revenue_range": "$80M-$100M",
  "key_products": ["CloudSync", "DataBridge", "AutoScale"],
  "description": "Cloud infrastructure SaaS company focused on DevOps automation for mid-market enterprises.",
  "confidence_score": 0.94
}
```

---

## View Results

After running the pipeline, generate an interactive HTML report:

```bash
python view_results.py
```

This creates `output.html` and opens it in your browser â€” a visual dashboard showing all extractions with confidence scores, metadata, and raw JSON.

ğŸ‘‰ **[View sample output](output.html)** â€” pre-generated from the 5 sample texts.

---

## Architecture

```
unstructured-to-json-llm-pipeline/
â”œâ”€â”€ pipeline.py              # Main orchestrator (~180 lines)
â”œâ”€â”€ models.py                # Pydantic v2 schemas
â”œâ”€â”€ view_results.py          # HTML report generator
â”œâ”€â”€ output.html              # Pre-generated results (viewable)
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ sample_texts/        # Input .txt files
â”‚       â”œâ”€â”€ acme_corp.txt
â”‚       â”œâ”€â”€ globex_industries.txt
â”‚       â”œâ”€â”€ initech_capital.txt
â”‚       â”œâ”€â”€ oceanic_analytics.txt
â”‚       â””â”€â”€ wayne_enterprises.txt
â”œâ”€â”€ extractions.db           # Auto-created SQLite output (gitignored)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### Key Design Decisions

| Decision | Why |
|----------|-----|
| Single `pipeline.py` | Readable, portfolio-friendly, no over-engineering |
| Pydantic v2 (not dataclasses) | Built-in JSON schema export for LLM prompts |
| SQLite (not Postgres) | Zero setup, runs anywhere, good enough for demo |
| httpx (not requests) | Async-ready, modern, clean timeout handling |
| Schema in system prompt | LLM stays focused; fewer hallucinations |

---

## Schemas

### CompanyProfile
| Field | Type | Description |
|-------|------|-------------|
| `company_name` | `str` | Legal or trade name |
| `industry` | `str` | Primary industry vertical |
| `headquarters` | `Optional[str]` | City, State / Country |
| `employee_count` | `Optional[int]` | Approximate headcount |
| `revenue_range` | `Optional[str]` | Annual revenue estimate |
| `key_products` | `list[str]` | Main products or services |
| `description` | `str` | 1-2 sentence summary |
| `confidence_score` | `float` | Extraction confidence (0â€“1) |

### BuyerProfile
| Field | Type | Description |
|-------|------|-------------|
| `company_name` | `str` | Firm name |
| `industry` | `str` | PE, VC, Corp Dev, etc. |
| `acquisition_interests` | `list[str]` | Target sectors / themes |
| `budget_range` | `Optional[str]` | Deal size or EBITDA range |
| `key_contacts` | `list[dict]` | Name, title, email |
| `deal_history` | `list[str]` | Recent transactions |
| `confidence_score` | `float` | Extraction confidence (0â€“1) |

---

## License

MIT License â€” see [LICENSE](LICENSE) for details.

---

*Built as a portfolio piece for Senior Data Engineer / AI Infrastructure roles.*
*Stack: Python Â· Pydantic v2 Â· Databricks Foundation Models Â· SQLite*
